\chapter{Multigrid}
\label{sec:mg}


\section{Multigrid methods}

Multigrid refers to a family of methods that several meshes with different resolutions in order to achieve high rates of convergence to solve linear systems.
These methods were developed to solve discretisation of elliptic partial differential equations, such as the Poisson problem.
The algorithm time-complexity is linear in the number of equations, making multigrid an optimal solver for many problems.
Multigrid can be applied iteratively as a solver or as a preconditioner to find the solution to a linear system.
For our problem, we will solve the Helmholtz equation by using multigrid as a preconditioner for the FGMRES iterative method.

First, let us motivate multigrid by considering the convergence behaviour of Jacobi iteration for a model problem.
The problem we will use for demonstration purposes is Laplace's equation in one dimension on the unit interval with homogeneous boundary conditions,
\begin{align}
	u''(x) = 0, \qquad u(0)=u(1)=0.
\end{align}
The exact solution to this problem is $u\equiv 0$.
Using finite differences to solve this problem, we discretise the equation with a second order centred difference scheme on a mesh with $N+2$ points.
The two end points $u_0$ and $u_{N+1}$ are known by the boundary values, so then we have for $1 \leq i \leq N$,
\begin{align}
	\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} = 0.
\end{align}
This discretisation results in a linear system of equations,
\begin{align}
	\begin{pmatrix}
		-2 	& 	1 	& & \\
		1	&	-2	&	1	& \\
		& 1 & \ddots & \ddots & \\
		 && \ddots & \ddots & 1 \\
		&&&1&-2
	\end{pmatrix} \begin{pmatrix}
		u_1 \\ u_2 \\ \vdots \\ u_{N-1} \\ u_N
	\end{pmatrix} = 0,
\end{align} 
which can now be solved iteratively using the Jacobi method.

For a matrix splitting of $A=D-(L+U)$, where $D$ consists of the diagonal entries of $A$ and $L+U$ consists of the remaining entries, the Jacobi iteration matrix is given by
\begin{align}
	B = -D^{-1} \left( L+U \right) = D^{-1} \left( D - A \right) = I - D^{-1} A
\end{align}

Denote by $u^{(i)}$ the $i^{\mathrm{th}}$ iterate of the Jacobi method.
Then the error in the solution can be written as
\begin{align}
	e^{(i)} = u - u^{(i)}.
\end{align}
Figure \ref{fig:error1} shows the initial error for a random initial guess $u^{0}$.
Applying several iterations of the Jacobi algorithm and examining the result, we see can see the primary difference in 
High frequency components of the error are damped rapidly by the Jacobi iteration, while the low frequency components of the error remain even after several iterations.
This can mean that for large problems, the error will only begin to reduce after several orders of magnitude of iterations.

The key point to note is that high frequency error components are characterised by the grid scale.
This can be seen using by expanding the error in terms of the eigenbasis of the Jacobi iteration matrix.

\begin{align}
	e^{(i)} = B^i e^{(0)} = \sum_{j=1}^{N} c_j \lambda^i \xi_j
\end{align}
For large values of $i$,
The eigenvalues approximately equal to one are damped slowly under iteration.
This occurs for the eigenvalues for some $j$.


To take advantage of this property, we can transfer the residual to a coarse grid.
On this grid, the previously low frequency error components become high frequency errors.
Performing few Jacobi iterations at this resolution should lead to a rapid reduction in the error.
Once these iterations have been completed, the solution is transferred back to the fine grid by an interpolation scheme.
On the fine grid, we apply a coarse grid correction that adjusts the error on the fine grid based on the damped errors from the coarse grid.

The description above is the outline for the two-grid method.
The two-grid method is the base algorithm on which many other multgrid methods are based \cite{hackbusch}.
For instance, the multigrid V-cycle may be thought of as a recursive scheme by performing an additional two-grid iteration on each coarser grid.
In this sense, we move from a fine mesh to coarser and coarser grids by restriction until we may solve the system directly.
Then we move the solution back to the finest level by prolongation until we are at the desired mesh level. 


\begin{figure}
	% Insert figure of error components for initial iteration phases, want to show low frequency errors are not dampened.
	% Insert figure for how the frequencies decay based on mesh level.
	\centering
	\subfloat[][Initial error in the solution.]{\label{fig:error1} \includegraphics[draft]{images/placeholder}}
	\\
	\subfloat[][Error in the solution after TODO damped Jacobi iterations.]{\includegraphics[draft]{images/placeholder}}
	\caption{Plots of the error between the exact and computed solutions to $u''(x)=0$ with boundary conditions $u(0)=u(1)=0$.
			 Notice here that high frequency errors are damped fast, while low frequencies persist after several iterations.}
\end{figure}



\subsection{Multigrid cycles}

Multigrid, as an iterative solver, involves performing cycles to reduce the residual in the problem.
The multigrid algorithm iteratively applies one of these cycles until a suitable convergence tolerance is reached.
The most common multigrid cycle is the V-cycle, and besides the two-grid method, it is the simplest to implement.
However there are many more cycles, each of which is a variation of the basic two-grid algorithm.
For example, other cycles include the W-cycle, F-cycle, and S-cycles.

Figure \ref{fig:mgcycles} shows a representation of how a single iteration of different cycles are applied.
The cycle begins on the first mesh.
Arrows pointing up indicate a prolongation to a finer mesh, and pointing down, a restriction to a coarser mesh.
On each mesh, smoothing is also performed.
A discussion of each of these components of the multigrid algorithm now follows.


\begin{figure}[h]
	\centering
	\subfloat[][\label{vcycle} V-cycle]{
	\begin{tikzpicture}[baseline]
	\def \n {2}
	\def \w {0.5}
	\def \r {0.9}
	\def \scale {0.8}
	\begin{scope}
		\foreach \x in {\n,...,1} {
		\node at (-\x*\w,\x) [circle,fill=black,scale=\scale] {};
		\draw [arrow] (-\x*\w,\x) -- (-\x*\w+\r*\w,\x-\r);
		}
		\foreach \x in {1,...,\n} {
		\node at (\x*\w,\x) [circle,fill=black,scale=\scale] {};
		}
			\foreach \x in {1,...,1} {
			\draw [arrow] (\x*\w,\x) -- (\x*\w+\r*\w, \x+\r);
		}
		\node at (0,0) [circle,fill=black,scale=\scale] {};
		\draw [arrow] (0,0) -- (\r*\w, \r);
	\end{scope}
	\end{tikzpicture}}
	\hfill
	\subfloat[][\label{wcycle} W-cycle]{
	\begin{tikzpicture}[baseline]
	\def \n {2}
	\def \w {0.5}
	\def \r {0.9}
	\def \scale {0.8}
	\begin{scope}
		\foreach \x in {\n,...,1} {
		\node at (-\x*\w,\x) [circle,fill=black,scale=\scale] {};
		\draw [arrow] (-\x*\w,\x) -- (-\x*\w+\r*\w, \x-\r);
		}
		\foreach \x in {0,...,\n} {
		\node at (2*\w + \x*\w,\x) [circle,fill=black,scale=\scale] {};
		}
			\foreach \x in {0,...,1} {
			\draw [arrow] (2*\w + \x*\w,\x) -- (2*\w + \x*\w+\r*\w, \x+\r);
		}
		\node at (0,0) [circle,fill=black,scale=\scale] {};
		\draw [arrow] (0,0) -- (\r*\w, \r);
		\node at (\w,1) [circle,fill=black,scale=\scale]{};
		\draw [arrow] (\w,1) -- (2*\w, 1-\r);
		
	\end{scope}

	\end{tikzpicture}}
	\hfill
	\subfloat[][\label{fmgcycle} F-cycle (full multigrid)]{
	\begin{tikzpicture}[baseline]
	\def \n {3}
	\def \w {0.5}
	\def \r {0.9}
	\def \scale {0.8}
	\begin{scope}
		
		\node at (0,0) [circle,fill=black,scale=\scale] {};
		\node at (\w,1) [circle,fill=black,scale=\scale] {};
		\node at (2*\w,0) [circle,fill=black,scale=\scale] {};
		\node at (3*\w,1) [circle,fill=black,scale=\scale] {};
		\node at (4*\w,2) [circle,fill=black,scale=\scale] {};
		\node at (5*\w,1) [circle,fill=black,scale=\scale] {};
		\node at (6*\w,0) [circle,fill=black,scale=\scale] {};
		\node at (7*\w,1) [circle,fill=black,scale=\scale] {};
		\node at (8*\w,2) [circle,fill=black,scale=\scale] {};
		
		\draw [arrow] (0,0) -- (\w, \r);
		\draw [arrow] (\w,1) -- (2*\w, 1-\r);
		\draw [arrow] (2*\w,0) -- (3*\w, \r);
		\draw [arrow] (3*\w,1) -- (4*\w, 1+\r);
		\draw [arrow] (4*\w, 2) -- (5*\w, 2-\r);
		\draw [arrow] (5*\w, 1) -- (6*\w, 1-\r);
		\draw [arrow] (6*\w, 0) -- (7*\w, \r);
		\draw [arrow] (7*\w, 1) -- (8*\w, 1+\r);
	\end{scope}
	\end{tikzpicture}}
	\caption{\label{fig:mgcycles} Examples of multigrid cycles on a sequence of meshes with three levels.}
\end{figure}







%------------------------------------------------

\section{Components of a multigrid algorithm}

For a complete multigrid algorithm, several components must exist.
Firstly, a hierarchy of meshes that define the multiple levels of the method, as well as transfer operators between the levels.
Next, on each level of the mesh, the Jacobian matrix resulting from the finite element discretisation must be formed in order to solve the problem at that level.
Finally, there must be  a suitable smoothing iteration procedure on each level.
In our case, this is GMRES, however any appropriate iterative solver will be sufficient.



\subsection{Smoothing}

Smoothing is not used to solve the problem, although on its own the smoother may be used as a convergent iterative solver.
Instead, the purpose is to reduce the high frequency errors of the solution on the current grid level.
As mentioned earlier, this is the key idea to multigrid algorithms.
Smoothing is typically done by a SOR method, such as the weighted Jacobi or Gauss-Seidel methods.

There are two opportunities to perform smoothing operations.
These occur before the restriction to the coarser level (pre-smoothing), then again after the coarse grid correction is applied to the solution on the finer level (post-smoothing).
Different multigrid cycles apply different rules to smoothing, such as when to smooth and how many smoothing iterations to perform.
For example, in the case of a V or W-cycle, both pre-smoothing and post-smoothing are performed.
However, in the case of an S-cycle, no pre-smoothing operations are performed, and only post-smoothing is applied.
For certain problems, this can improve performance because of the reduction of the smoothing operations \cite{iyengar}.

The particular choice of smoother in \oomph is between the complex damped Jacobi method and GMRES.
Alternatively, one could choose to implement their own smoother to override the default behaviour.




\subsection{Prolongation and restriction}

The procedures for transferring the solution between mesh levels are known as prolongation and restriction.
Prolongation, otherwise known as interpolation, is the process of transferring the solution up a level from a coarse grid to a finer grid.
Restriction, sometimes called coarsening, is the operation that acts as the inverse to prolongation.
This process moves the solution down a grid level from a fine grid to a coarser grid.
These operators are created using interpolation methods between elements on the different meshes.

Let $\Omega^h$ and $\Omega^{2h}$ be the meshes on the fine and coarse levels, respectively, of the domain $\Omega$.
Denote by $V^{h}$ and $V^{2h}$ the finite element spaces on their respective meshes.
The mesh $\Omega^{h}$ is obtained through refinement of $\Omega^{2h}$, or equivalently, $\Omega^{2h}$ is obtained through unrefinement of $\Omega^{h}$.
Since $\Omega^{2h}\subset \Omega^{h}$, it is the case that $V^{2h}\subset V^h$.
Then we define the prolongation operator by
\begin{align}
	I^h_{2h} \, : \, V^{2h} \rightarrow V^h.
\end{align}
Likewise, we define restriction operator,
\begin{align}
	I^{2h}_h \, : \, V^{h} \rightarrow V^{2h}.
\end{align}

The two operators act on element basis functions, which take nodal values from their source mesh level to the destination mesh level.
Figure \ref{fig:pro_res_ops} is a representation of how the transfer matrices act on points in the mesh.

\begin{figure}[h]
	\centering
	\scalebox{0.4}{
	\begin{tikzpicture}[baseline,decoration={markings,mark=at position 0.08 with
		{\arrow[scale=5,>=stealth]{<}}}]
	\centering
	\begin{scope}
	
	% define constants
	\def \w {8}
	\def \d {4}
	\def \textoff {3}
	\def \r {6}
	
	% Draw the grids
	\draw[step=2,black,very thin] (0,0) grid (\w,\w);
	\draw[step=4,black,very thin] (\w+\d,0) grid (2*\w+\d,8);
	\draw[step=8,black,very thin] (2*\w+2*\d,0) grid (3*\w+2*\d,8);
	
	% First text
	\node[anchor=center,scale=2.5] at (\w+\d/2,\w+\textoff) {Restriction};
	\node[anchor=center,scale=2.5] at (\w+\d/2.1,-\textoff) {Prolongation};
	
	% Second text
	\node[anchor=center,scale=2.5] at (2*\w+1.5*\d,\w+\textoff) {Restriction};
	\node[anchor=center,scale=2.5] at (2*\w+1.5*\d,-\textoff) {Prolongation};
	
	% Top arrows
	\draw[postaction={decorate}] (\w+\d+\r/4,\w+0.5) arc (55:125:\r);
	\draw[postaction={decorate}] (2*\w+2*\d+\r/4,\w+0.5) arc (55:125:\r);
	
	% Bottom arrows
	\draw[postaction={decorate}] (\w-\r/4,-0.5) arc (180+55:180+125:\r);
	\draw[postaction={decorate}] (2*\w+\d-\r/4,-0.5) arc (180+55:180+125:\r);
	
	\end{scope}
	\end{tikzpicture}
	}
	
	\caption{\label{fig:pro_res_ops} Prolongation and restriction operators moving between mesh levels.}
\end{figure}

The transfer operators are all created in the setup phase for multigrid, and can be created once the meshes have been generated.
Two transfer operators are required for each mesh level, except for on the finest and coarsest levels.
In these cases, a restriction for the coarsest level and a prolongation for the finest level are not needed.
For each possible level of refinement, we create a prolongation matrix.
Consider a given level of refinement and call the mesh at this level the coarse mesh and the one at the next level the fine mesh.
Loop over all of the elements in the fine mesh, and then for each node in the element, compute the contribution to the matrix that the node takes from its posisiton in the coarse mesh.
The total contribution is put into the transfer matrix, taking the solution from the coarse mesh to the fine mesh.
The restriction matrix can then be defined to be the transpose of the prolongation matrix.





%------------------------------------------------

\section{Multigrid as a preconditioner}
\label{sec:precond}

\subsection{Block preconditioning}

% Talk about block preconditioning in regards to complex Helmholtz problem
% The block structure, derivation...
% Enumeration of the unknowns and equations. Real part first, imaginary part second

As mentioned in chapter \ref{sec:problem}, the Helmholtz equation we are interested in is complex-valued.
Since \oomph does not natively handle complex arithmetic, complex numbers are instead stored as 2D vectors.
The first component of the vector is the real part of the complex number, and the second component is the imaginary part.

For a specific enumeration of the unknowns, we can obtain a matrix whose structure allows us to solve the problem more efficiently.
Taking into account the order of the \oomph complex number-vector representation, we first compute the contribution for all of the real unknowns, then the contribution for the imaginary unknowns.
This ordering gives rise to a Jacobian matrix with a block structure
\begin{align}
	A = \begin{pmatrix}
		A_r & -A_c \\ A_c & A_r
	\end{pmatrix}.
\end{align}
Here, $A_r$ is the real part of the discretisation and $A_c$ is the imaginary part.

Given a matrix with a block structure, we use a preconditioner that acts on the blocks of the matrix.
This is aptly named a block preconditioner.
A framework for block preconditioning exists within \oomph, so then all that is required is to extend this interface using the specifics of our preconditioner.
The linear solver can then use the block preconditioner to solve the linear system.


\subsection{Multigrid preconditioning}

Since multigrid does not perform well for the Helmholtz equation for moderate values of $k^2$, another approach is required.
In order to take advantage of the benefits of multigrid, we instead solve a nearby complex-shifted problem.
Recall the CSLP \eqref{eqn:cslp},
\begin{align}
	\nabla^2 u + \left[(1+i\alpha)k^2 - \frac{N^2}{r^2}\right] u = 0.
\end{align}
This is not the problem we want to solve, but instead is close enough that we can use the solution to this as the preconditioner for another iterative method.
Furthermore, the issues with multigrid for the standard Helmholtz equation are overcome with the shifted problem.
Taking $\alpha=0$ as the shift, we recover back the Helmholtz equation.
Therefore, by altering this parameter we can control exactly which problem is solved.

To solve the problem then, we use the Krylov subspace method GMRES to solve the Helmholtz equation with multigrid as the preconditioner.
There is an issue however that the preconditioner is not constant between iterations.
This is due to using GMRES as the smoother for multigrid, and is noted in \cite{elman}.
Because of this we instead use FGMRES, the flexible version of the GMRES method for the outer iteration.
This method allows for a nonconstant preconditioner.

To summarise, the FGMRES algorithm is used to solve the Fourier decomposed Helmholtz equation by taking $\alpha=0$.
This is the outer iteration, used to solve $Ax=b$.
Multigrid is used as the preconditioner for FGMRES, solving the shifted Laplacian problem, using GMRES as the smoother.
The value of the shift parameter for the preconditioner is taken to be $\alpha=0.5$.